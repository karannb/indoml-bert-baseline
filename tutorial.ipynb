{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMQMimaytq7-"
      },
      "source": [
        "# BERT Baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzGfg3dPtq8I"
      },
      "source": [
        "## DataThon @ IndoML'24\n",
        "\n",
        "This tutorial will walk you through a very simple BERT based baseline for the [DataThon](https://sites.google.com/view/datathon-indoml24) Challenge at IndoML'24.\n",
        "Feel free to play around with the repository, once you are done with this tutorial, it has been developed to work with multiple GPUs as well.\n",
        "At the end, you might also be able to make your first submission (albeit a very bad one!).\n",
        "\n",
        "### Table of Contents:\n",
        "\n",
        "1. [Preprocessing](#preprocessing)\n",
        "2. [Dataset Creation](#dataset-creation)\n",
        "3. [BERT Models](#bert)\n",
        "4. [Training](#training)\n",
        "5. [Evaluation](#evaluation)\n",
        "\n",
        "Please feel free to create a PR if you find any bugs or need help with running this code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWaHVbpPtq8L",
        "outputId": "957266b8-c956-47e1-c93e-24d91f6904f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'indoml-bert-baseline' already exists and is not an empty directory.\n",
            "Requirement already satisfied: numpy==1.23.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (1.23.5)\n",
            "Requirement already satisfied: pandas==1.5.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (1.5.3)\n",
            "Requirement already satisfied: scikit_learn==1.2.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (1.2.1)\n",
            "Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (2.0.1)\n",
            "Requirement already satisfied: tqdm==4.64.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (4.64.1)\n",
            "Requirement already satisfied: transformers==4.33.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (4.33.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3->-r requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3->-r requirements.txt (line 2)) (2024.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit_learn==1.2.1->-r requirements.txt (line 3)) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit_learn==1.2.1->-r requirements.txt (line 3)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn==1.2.1->-r requirements.txt (line 3)) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r requirements.txt (line 4)) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r requirements.txt (line 4)) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r requirements.txt (line 4)) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r requirements.txt (line 4)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r requirements.txt (line 4)) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r requirements.txt (line 4)) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r requirements.txt (line 4)) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r requirements.txt (line 4)) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r requirements.txt (line 4)) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r requirements.txt (line 4)) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r requirements.txt (line 4)) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r requirements.txt (line 4)) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r requirements.txt (line 4)) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r requirements.txt (line 4)) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r requirements.txt (line 4)) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r requirements.txt (line 4)) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r requirements.txt (line 4)) (2.0.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.33.2->-r requirements.txt (line 6)) (0.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.33.2->-r requirements.txt (line 6)) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.33.2->-r requirements.txt (line 6)) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.33.2->-r requirements.txt (line 6)) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.33.2->-r requirements.txt (line 6)) (2.32.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.33.2->-r requirements.txt (line 6)) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.33.2->-r requirements.txt (line 6)) (0.4.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->-r requirements.txt (line 4)) (71.0.4)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->-r requirements.txt (line 4)) (0.44.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->-r requirements.txt (line 4)) (3.30.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->-r requirements.txt (line 4)) (18.1.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.33.2->-r requirements.txt (line 6)) (2024.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas==1.5.3->-r requirements.txt (line 2)) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1->-r requirements.txt (line 4)) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.33.2->-r requirements.txt (line 6)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.33.2->-r requirements.txt (line 6)) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.33.2->-r requirements.txt (line 6)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.33.2->-r requirements.txt (line 6)) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->-r requirements.txt (line 4)) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "# Please run this cell on colab, you can skip this if you are running locally.\n",
        "!git clone https://github.com/karannb/indoml-bert-baseline.git\n",
        "!cd indoml-bert-baseline/ && pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLokjrk5tq8O"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1O32TPMtq8O"
      },
      "source": [
        "Before preprocessing we need to get our data, please download it from [here](https://codalab.lisn.upsaclay.fr/competitions/19907#participate) after registering for the challenge.\n",
        "You can store it in any directory, but ideally store it in a new directory `data/`.\n",
        "Once you have the data running, the next cell will pre-process the data to have it in the format we have designed our `torch.utils.data.Dataset` objects, you can obviously change these as well.\n",
        "Feel free to got through the code if you want to change anything."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mk6t3NX_tq8P"
      },
      "source": [
        "### Preprocess and Categorize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip input_data.zip -d indoml-bert-baseline/data/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2rvRM92xv5y",
        "outputId": "6a27d44a-c7a5-49e4-d63c-2d012a530370"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  input_data.zip\n",
            "replace indoml-bert-baseline/data/attribute_test.data? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: indoml-bert-baseline/data/attribute_test.data  \n",
            "  inflating: indoml-bert-baseline/data/attribute_train.data  \n",
            "  inflating: indoml-bert-baseline/data/attribute_train.solution  \n",
            "  inflating: indoml-bert-baseline/data/attribute_val.data  \n",
            "  inflating: indoml-bert-baseline/data/attribute_val.solution  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd indoml-bert-baseline/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtupLoyUzGdk",
        "outputId": "0bc2b887-9a2b-4221-b2be-09cf3c4bad90"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/indoml-bert-baseline\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IYtQe0Xtq8P",
        "outputId": "37bf83fa-ccb8-44bb-9259-04ae91d980f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/test.json already exists, skipped.\n",
            "data/val.json already exists, skipped.\n",
            "data/val_sol.json already exists, skipped.\n",
            "data/train.json already exists, skipped.\n",
            "data/train_sol.json already exists, skipped.\n",
            "Attribute: details_Brand has 5066 unique values.\n",
            "Maps for details_Brand already exist, skipped.\n",
            "Attribute: L0_category has 27 unique values.\n",
            "Maps for L0_category already exist, skipped.\n",
            "Attribute: L1_category has 163 unique values.\n",
            "Maps for L1_category already exist, skipped.\n",
            "Attribute: L2_category has 612 unique values.\n",
            "Maps for L2_category already exist, skipped.\n",
            "Attribute: L3_category has 1252 unique values.\n",
            "Maps for L3_category already exist, skipped.\n",
            "Attribute: L4_category has 962 unique values.\n",
            "Maps for L4_category already exist, skipped.\n"
          ]
        }
      ],
      "source": [
        "from src.preprocess import preprocess_fn, categorize\n",
        "\n",
        "# this will preprocess the data to a particular format (in json)\n",
        "preprocess_fn(\"attribute_test.data\", \"data\")\n",
        "preprocess_fn(\"attribute_val.data\", \"data\")\n",
        "preprocess_fn(\"attribute_val.solution\", \"data\")\n",
        "preprocess_fn(\"attribute_train.data\", \"data\")\n",
        "preprocess_fn(\"attribute_train.solution\", \"data\")\n",
        "\n",
        "\n",
        "# this will create maps of index2class and class2index for all columns or outputs\n",
        "for col in ['details_Brand', 'L0_category', 'L1_category', 'L2_category', 'L3_category', 'L4_category']:\n",
        "    categorize(col)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sr65JTd5tq8Q"
      },
      "source": [
        "## Dataset Creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBvgDg8Utq8Q"
      },
      "source": [
        "Now we will create PyTorch Datasets for convinient DataLoading (across multiple devices as well).\n",
        "We would strongly recommend you to start modifying stuff here in case you want to use a BERT baseline itself, we have also added a `TODO: CAN CHANGE HERE` where we thought modifications are possible.\n",
        "DO NOT USE `trim=True` when you are training your own model! It is only helpful for debugging purposes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gG3j8wHLtq8R",
        "outputId": "a1393759-6d72-4bc0-a360-ee99ea5dd283"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading train data: 100%|██████████| 443499/443499 [00:00<00:00, 750706.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 'na' as the label, removing examples with 'na' label.\n",
            "Original data has 443499 examples.\n",
            "Data loaded in 0.058 minutes.\n",
            "train data has 1000 examples.\n",
            "{'input': 'Product Name: FEL-PRO 60977 Throttle Body Gasket, Sold at store: Fel-Pro, Manufactured by: FEL-PRO', 'output': 695, 'id': 188905}\n",
            "{'input': ['Product Name: Microsoft Surface Book 2 Sleeve Case Evecase Slim Neoprene Pouch Carrying Laptop Bag for 2017 Microsoft Surface Book 2 / 1 13.5inch Chromebook - Black, Sold at store: Evecase, Manufactured by: Evecase', 'Product Name: GSP NCV36558 CV Axle Shaft Assembly - Right Front (Passenger Side), Sold at store: GSP, Manufactured by: GSP'], 'output': tensor([932, 193]), 'ids': tensor([94512, 61450], dtype=torch.int32)}\n"
          ]
        }
      ],
      "source": [
        "from src.dataset import ReviewsDataset, ReviewsDataLoader\n",
        "\n",
        "# this is just a simple interface run\n",
        "dataset = ReviewsDataset(data_dir=\"data/\", split=\"train\", output=\"L4_category\", trim=True)\n",
        "print(dataset[0])\n",
        "\n",
        "dataloader = ReviewsDataLoader(dataset, batch_size=2, shuffle=True)\n",
        "\n",
        "for batch in dataloader:\n",
        "    print(batch)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9Sl2J6Rtq8S"
      },
      "source": [
        "## BERT Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3dOad42tq8S"
      },
      "source": [
        "This is a simple script to download a BERT model ans it's tokenizer, you can also play around with different types of BERT models from HuggingFace.\n",
        "We stick to the basic one [here](https://huggingface.co/google-bert/bert-base-uncased).\n",
        "Please save them appropriately, or modify the path in the `trainer.py`, by default it should be saved in `bert-model/` and `bert-tokenizer/`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmrPShhKtq8S",
        "outputId": "b7fba0fd-67cf-4d36-ffde-e911ab946eeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from src.downloadBERT import download\n",
        "\n",
        "# this function will download the model and tokenizer\n",
        "download()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTERJiy3tq8T"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BEO7FR8tq8T"
      },
      "source": [
        "Now the interesting part, training.\n",
        "Note that there are **several** parameters that can be modified here, from learning rate to batch size to the optimizer used, weight decay, etc..\n",
        "Apart from that, the code also doesn't have checkpointing as of now, you will probably need that.\n",
        "You can also change the criteria for best model selection (currently f1-score).\n",
        "Again, remember to NOT TRIM when you are actually training your model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkXJ19lktq8T",
        "outputId": "d72cadef-73e0-4790-b5e8-23549cea74de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on cuda\n",
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading train data: 100%|██████████| 443499/443499 [00:00<00:00, 678456.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded in 0.064 minutes.\n",
            "train data has 1000 examples.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading val data: 100%|██████████| 95035/95035 [00:00<00:00, 566259.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded in 0.013 minutes.\n",
            "val data has 200 examples.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading test data: 100%|██████████| 95036/95036 [00:00<00:00, 753410.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded in 0.008 minutes.\n",
            "test data has 95036 examples.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ./bert-model/ and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:32<00:00,  3.85it/s]\n",
            "100%|██████████| 25/25 [00:06<00:00,  3.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.0950, Precision: 0.9289, Recall: 0.1160, F1: 0.0516\n",
            "Epoch 2/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:31<00:00,  3.95it/s]\n",
            "100%|██████████| 25/25 [00:06<00:00,  4.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.1650, Precision: 0.7659, Recall: 0.3190, F1: 0.0938\n",
            "Epoch 3/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:31<00:00,  3.96it/s]\n",
            "100%|██████████| 25/25 [00:06<00:00,  3.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.1900, Precision: 0.7228, Recall: 0.3806, F1: 0.1170\n",
            "Epoch 4/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:31<00:00,  3.93it/s]\n",
            "100%|██████████| 25/25 [00:06<00:00,  3.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.2250, Precision: 0.7560, Recall: 0.3648, F1: 0.1421\n",
            "Epoch 5/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:31<00:00,  3.96it/s]\n",
            "100%|██████████| 25/25 [00:06<00:00,  3.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.2450, Precision: 0.7156, Recall: 0.4237, F1: 0.1502\n",
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading train data: 100%|██████████| 443499/443499 [00:00<00:00, 514507.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded in 0.073 minutes.\n",
            "train data has 1000 examples.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading val data: 100%|██████████| 95035/95035 [00:00<00:00, 609729.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded in 0.013 minutes.\n",
            "val data has 200 examples.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading test data: 100%|██████████| 95036/95036 [00:00<00:00, 681699.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded in 0.007 minutes.\n",
            "test data has 95036 examples.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ./bert-model/ and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:31<00:00,  3.93it/s]\n",
            "100%|██████████| 25/25 [00:06<00:00,  3.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.5500, Precision: 0.7930, Recall: 0.3432, F1: 0.3255\n",
            "Epoch 2/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:31<00:00,  3.98it/s]\n",
            "100%|██████████| 25/25 [00:06<00:00,  4.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.6550, Precision: 0.8066, Recall: 0.4700, F1: 0.4880\n",
            "Epoch 3/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:31<00:00,  3.99it/s]\n",
            "100%|██████████| 25/25 [00:06<00:00,  3.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.6200, Precision: 0.7147, Recall: 0.4003, F1: 0.3874\n",
            "Epoch 4/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:31<00:00,  3.95it/s]\n",
            "100%|██████████| 25/25 [00:06<00:00,  3.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.6900, Precision: 0.7597, Recall: 0.4836, F1: 0.4702\n",
            "Epoch 5/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:31<00:00,  3.97it/s]\n",
            "100%|██████████| 25/25 [00:06<00:00,  3.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.7100, Precision: 0.7376, Recall: 0.5806, F1: 0.5775\n",
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading train data: 100%|██████████| 443499/443499 [00:00<00:00, 696781.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded in 0.063 minutes.\n",
            "train data has 1000 examples.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading val data: 100%|██████████| 95035/95035 [00:00<00:00, 579742.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded in 0.012 minutes.\n",
            "val data has 200 examples.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading test data: 100%|██████████| 95036/95036 [00:00<00:00, 789456.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded in 0.008 minutes.\n",
            "test data has 95036 examples.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ./bert-model/ and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:31<00:00,  3.95it/s]\n",
            "100%|██████████| 25/25 [00:06<00:00,  3.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.3550, Precision: 0.8312, Recall: 0.1777, F1: 0.1048\n",
            "Epoch 2/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:31<00:00,  3.96it/s]\n",
            "100%|██████████| 25/25 [00:06<00:00,  3.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.4400, Precision: 0.7704, Recall: 0.2859, F1: 0.2131\n",
            "Epoch 3/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:31<00:00,  3.98it/s]\n",
            "100%|██████████| 25/25 [00:06<00:00,  3.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.4850, Precision: 0.8116, Recall: 0.3562, F1: 0.2911\n",
            "Epoch 4/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:31<00:00,  3.95it/s]\n",
            "100%|██████████| 25/25 [00:06<00:00,  3.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.4900, Precision: 0.8210, Recall: 0.3085, F1: 0.2704\n",
            "Epoch 5/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:31<00:00,  3.96it/s]\n",
            "100%|██████████| 25/25 [00:06<00:00,  3.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.5300, Precision: 0.7769, Recall: 0.4116, F1: 0.3406\n",
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading train data: 100%|██████████| 443499/443499 [00:00<00:00, 677091.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded in 0.060 minutes.\n",
            "train data has 1000 examples.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading val data: 100%|██████████| 95035/95035 [00:00<00:00, 583853.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded in 0.012 minutes.\n",
            "val data has 200 examples.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading test data: 100%|██████████| 95036/95036 [00:00<00:00, 455465.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded in 0.011 minutes.\n",
            "test data has 95036 examples.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ./bert-model/ and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:31<00:00,  3.94it/s]\n",
            "100%|██████████| 25/25 [00:06<00:00,  3.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.2250, Precision: 0.8527, Recall: 0.1659, F1: 0.0904\n",
            "Epoch 2/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:31<00:00,  3.97it/s]\n",
            "100%|██████████| 25/25 [00:06<00:00,  4.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.2600, Precision: 0.8216, Recall: 0.2291, F1: 0.1346\n",
            "Epoch 3/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:31<00:00,  3.98it/s]\n",
            "100%|██████████| 25/25 [00:06<00:00,  3.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.3350, Precision: 0.8145, Recall: 0.3064, F1: 0.1965\n",
            "Epoch 4/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:31<00:00,  3.95it/s]\n",
            "100%|██████████| 25/25 [00:06<00:00,  3.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.3250, Precision: 0.7713, Recall: 0.3138, F1: 0.1837\n",
            "Epoch 5/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:31<00:00,  3.97it/s]\n",
            "100%|██████████| 25/25 [00:06<00:00,  3.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.3650, Precision: 0.6890, Recall: 0.3888, F1: 0.2206\n",
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading train data: 100%|██████████| 443499/443499 [00:00<00:00, 709655.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 'na' as the label, removing examples with 'na' label.\n",
            "Original data has 443499 examples.\n",
            "Data loaded in 0.065 minutes.\n",
            "train data has 1000 examples.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading val data: 100%|██████████| 95035/95035 [00:00<00:00, 580503.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 'na' as the label, removing examples with 'na' label.\n",
            "Original data has 95035 examples.\n",
            "Data loaded in 0.013 minutes.\n",
            "val data has 200 examples.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading test data: 100%|██████████| 95036/95036 [00:00<00:00, 734028.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded in 0.007 minutes.\n",
            "test data has 95036 examples.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ./bert-model/ and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:31<00:00,  3.94it/s]\n",
            "100%|██████████| 25/25 [00:06<00:00,  3.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.0800, Precision: 0.9334, Recall: 0.0793, F1: 0.0399\n",
            "Epoch 2/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:31<00:00,  3.96it/s]\n",
            "100%|██████████| 25/25 [00:06<00:00,  4.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.1200, Precision: 0.8208, Recall: 0.1733, F1: 0.0469\n",
            "Epoch 3/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:31<00:00,  3.97it/s]\n",
            "100%|██████████| 25/25 [00:06<00:00,  3.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.1700, Precision: 0.7229, Recall: 0.2894, F1: 0.0784\n",
            "Epoch 4/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:31<00:00,  3.95it/s]\n",
            "100%|██████████| 25/25 [00:06<00:00,  3.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.2450, Precision: 0.7181, Recall: 0.3311, F1: 0.1062\n",
            "Epoch 5/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:31<00:00,  3.97it/s]\n",
            "100%|██████████| 25/25 [00:06<00:00,  3.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.1950, Precision: 0.7060, Recall: 0.3014, F1: 0.1033\n",
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading train data: 100%|██████████| 443499/443499 [00:00<00:00, 679673.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 'na' as the label, removing examples with 'na' label.\n",
            "Original data has 443499 examples.\n",
            "Data loaded in 0.058 minutes.\n",
            "train data has 1000 examples.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading val data: 100%|██████████| 95035/95035 [00:00<00:00, 534864.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 'na' as the label, removing examples with 'na' label.\n",
            "Original data has 95035 examples.\n",
            "Data loaded in 0.012 minutes.\n",
            "val data has 200 examples.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading test data: 100%|██████████| 95036/95036 [00:00<00:00, 704250.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded in 0.008 minutes.\n",
            "test data has 95036 examples.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ./bert-model/ and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:31<00:00,  3.94it/s]\n",
            "100%|██████████| 25/25 [00:06<00:00,  3.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.1200, Precision: 0.9232, Recall: 0.0897, F1: 0.0376\n",
            "Epoch 2/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:31<00:00,  3.96it/s]\n",
            "100%|██████████| 25/25 [00:06<00:00,  4.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.1950, Precision: 0.8193, Recall: 0.2324, F1: 0.1028\n",
            "Epoch 3/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:31<00:00,  3.97it/s]\n",
            "100%|██████████| 25/25 [00:06<00:00,  3.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.2500, Precision: 0.7281, Recall: 0.3413, F1: 0.1329\n",
            "Epoch 4/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:31<00:00,  3.95it/s]\n",
            "100%|██████████| 25/25 [00:06<00:00,  3.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.3450, Precision: 0.7118, Recall: 0.4087, F1: 0.2040\n",
            "Epoch 5/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:31<00:00,  3.98it/s]\n",
            "100%|██████████| 25/25 [00:06<00:00,  3.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.2950, Precision: 0.6880, Recall: 0.3940, F1: 0.1797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from src.trainer import Trainer\n",
        "\n",
        "# note that this code IS NOT going to run on multiple GPUs,\n",
        "# please see the README / trainer.py for that. If you run\n",
        "# on colab, it will utilize the GPU there. Please raise an\n",
        "# issue if you don't see that happen.\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Running on {device}\")\n",
        "\n",
        "trainers = {}\n",
        "for col in ['details_Brand', 'L0_category', 'L1_category', 'L2_category', 'L3_category', 'L4_category']:\n",
        "    print(\"*\"*88)\n",
        "    print(f\"Training for {col}\")\n",
        "    print(\"*\"*88)\n",
        "    trainers[col] = Trainer(data_dir=\"data/\", device=device, output=col, trim=True)\n",
        "    trainers[col].train()\n",
        "    print(f\"Training finished for {col}\")\n",
        "    print(\"*\"*88)\n",
        "    # print(f\"Testing on {col}\")\n",
        "    # print(\"*\"*88)\n",
        "    # trainer[col].test()\n",
        "    # print(f\"Testing finished for {col}\")\n",
        "    # print(\"*\"*88)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsSTphSUtq8U"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfQ8qZWetq8W"
      },
      "source": [
        "We have also provided utility evaluation functions (which we use for validation), to judge your model.\n",
        "Please note that if you want to perform model selection based on `item accuracy` (the main metric for the contest), since we are training 6 different models for 6 different columns, to get the `item accuracy` you need to store results from the validation run how we have done for the test run.\n",
        "To make a valid submission, just run the previous code cell with the testing lines uncommented and then you can use the next cell to generate a valid submission. (NOTE: this takes\n",
        "very long, as the test output must be on the entire test dataset ~49 minutes on one GPU on colab, you can reduce this by using a bigger batch size probably)\n",
        "The next cell will generate a zip file that you can upload to CodaLab."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from src.evaluate import postprocess\n",
        "\n",
        "# postprocess()"
      ],
      "metadata": {
        "id": "7ohemJY9MTFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjZmMWkGtq8Z"
      },
      "source": [
        "## Thank you!\n",
        "Repository and tutorial by [Karan Bania](https://karannb.github.io)."
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}