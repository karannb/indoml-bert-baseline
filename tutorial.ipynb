{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataThon @ IndoML'24\n",
    "\n",
    "This tutorial will walk you through a very simple BERT based baseline for the [DataThon](https://sites.google.com/view/datathon-indoml24) Challenge at IndoML'24.\n",
    "Feel free to play around with the repository, once you are done with this tutorial, it has been developed to work with multiple GPUs as well.\n",
    "At the end, you will also be able to make your first submission (albeit a very bad one!).\n",
    "\n",
    "### Table of Contents: \n",
    "\n",
    "1. [Preprocessing](#preprocessing)\n",
    "2. [Dataset Creation](#dataset-creation)\n",
    "3. [BERT Models](#bert)\n",
    "4. [Training](#training)\n",
    "5. [Evaluation](#evaluation)\n",
    "\n",
    "Please feel free to create a PR if you find any bugs or need help with running this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Please run this cell on colab, you can skip this if you are running locally.\n",
    "# !git clone https://github.com/karannb/indoml-bert-baseline.git\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"./\") # easier relative imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before preprocessing we need to get our data, please download it from [here](https://codalab.lisn.upsaclay.fr/competitions/19907#participate) after registering for the challenge.\n",
    "You can store it in any directory, but ideally store it in a new directory `data/`.\n",
    "Once you have the data running, the next cell will pre-process the data to have it in the format we have designed our `torch.utils.data.Dataset` objects, you can obviously change these as well.\n",
    "Feel free to got through the code if you want to change anything."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess and Categorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from src.preprocess import preprocess_fn, categorize\n",
    "\n",
    "# this will preprocess the data to a particular format (in json)\n",
    "preprocess_fn(\"attrebute_test.data\", \"data\")\n",
    "preprocess_fn(\"attrebute_val.data\", \"data\")\n",
    "preprocess_fn(\"attrebute_val.solution\", \"data\")\n",
    "preprocess_fn(\"attrebute_train.data\", \"data\")\n",
    "preprocess_fn(\"attrebute_train.solution\", \"data\")\n",
    "\n",
    "\n",
    "# this will create maps of index2class and class2index for all columns or outputs\n",
    "for col in ['details_Brand', 'L0_category', 'L1_category', 'L2_category', 'L3_category', 'L4_category']:\n",
    "    categorize(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create PyTorch Datasets for convinient DataLoading (across multiple devices as well).\n",
    "We would strongly recommend you to start modifying stuff here in case you want to use a BERT baseline itself, we have also added a `TODO: CAN CHANGE HERE` where we thought modifications are possible.\n",
    "DO NOT USE `trim=True` when you are training your own model! It is only helpful for debugging purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from src.dataset import ReviewsDataset, ReviewsDataLoader\n",
    "\n",
    "# this is just a simple interface run\n",
    "dataset = ReviewsDataset(data_dir=\"data/\", split=\"test\", output=\"L4_category\", trim=True)\n",
    "print(dataset[0])\n",
    "\n",
    "dataloader = ReviewsDataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "for batch in dataloader:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple script to download a BERT model ans it's tokenizer, you can also play around with different types of BERT models from HuggingFace. \n",
    "We stick to the basic one [here](https://huggingface.co/google-bert/bert-base-uncased).\n",
    "Please save them appropriately, or modify the path in the `trainer.py`, by default it should be saved in `bert-model/` and `bert-tokenizer/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from src.downloadBERT import download\n",
    "\n",
    "# this function will download the model and tokenizer\n",
    "download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the interesting part, training.\n",
    "Note that there are **several** parameters that can be modified here, from learning rate to batch size to the optimizer used, weight decay, etc..\n",
    "Apart from that, the code also doesn't have checkpointing as of now, you will probably need that.\n",
    "You can also change the criteria for best model selection (currently f1-score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from src import trainer\n",
    "\n",
    "# note that this code IS NOT going to run on multiple GPUs, \n",
    "# please see the README / trainer.py for that. If you run\n",
    "# on colab, it will utilize the GPU there. Please raise an\n",
    "# issue if you don't see that happen.\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Running on {device}\")\n",
    "\n",
    "trainer = Trainer(data_dir=\"data/\", device=device, output=\"details_Brand\", trim=True)\n",
    "trainer.train()\n",
    "trainer.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have also provided utility evaluation functions (which we use for validation), to judge your model.\n",
    "Please note that since we are ideally training 6 different models for 6 different columns to get the `item accuracy` you need to store results from the validation run how we have done for the test run.\n",
    "To make a valid submission, just run the previous code cell 6 times with all the 6 columns as the output once, then you can use the next cell to generate a valid submission.\n",
    "The next cell will generate a zip file that you can upload to CodaLab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from src.evaluate import postprocess\n",
    "\n",
    "postprocess(\"outputs/results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thank you!\n",
    "Repository and tutorial by [Karan Bania](https://karannb.github.io)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
